{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Quality Dataset \n",
    "\n",
    "## Data Description\n",
    "\n",
    "### Red Wine Quality - Parameters\n",
    "* fixed.acidity (tartaric acid - g / dm^3): most acids involved with wine or fixed or nonvolatile (do not evaporate readily) \n",
    "* volatile.acidity (acetic acid - g / dm^3): the amount of acetic acid in wine, which at too high of levels can lead to an unpleasant, vinegar taste \n",
    "* citric.acid (g / dm^3): the amount of acetic acid in wine, which at too high of levels can lead to an unpleasant, vinegar taste \n",
    "* residual.sugar (g / dm^3): the amount of sugar remaining after fermentation stops, it's rare to find wines with less than 1 gram/liter and wines with greater than 45 grams/liter are considered sweet \n",
    "* chlorides (sodium chloride - g / dm^3): the amount of salt in the wine \n",
    "* free.sulfur.dioxide (mg / dm^3): the free form of SO2 exists in equilibrium between molecular SO2 (as a dissolved gas) and bisulfite ion; it prevents microbial growth and the oxidation of wine \n",
    "* total.sulfur.dioxide (mg / dm^3): amount of free and bound forms of S02; in low concentrations, SO2 is mostly undetectable in wine, but at free SO2 concentrations over 50 ppm, SO2 becomes evident in the nose and taste of wine \n",
    "* density (g / cm^3): the density of water is close to that of water depending on the percent alcohol and sugar content \n",
    "* pH: describes how acidic or basic a wine is on a scale from 0 (very acidic) to 14 (very basic); most wines are between 3-4 on the pH scale \n",
    "* sulphates (potassium sulphate - g / dm3): a wine additive which can contribute to sulfur dioxide gas (S02) levels, wich acts as an antimicrobial and antioxidant \n",
    "* alcohol (% by volume): the percent alcohol content of the wine \n",
    "* quality: quality score between 0 and 10\n",
    "\n",
    "### Objective.\n",
    "\n",
    "* To explore the physiocochemical properties of red wine\n",
    "* To determine an optimal machine learning model for red wine quality classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import librarires\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Sklearn moduels.\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include any additional modules libraries your code might need here.\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to load the data from file. Here we use the pandas library to read the csv file. \n",
    "datafile = \"../data/red-wine-dataset/wineQualityReds.csv\"\n",
    "wine_df = pd.read_csv(datafile)\n",
    "wine_df.drop(wine_df.columns[0],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training and testing set using the sklearn function train_test_split\n",
    "# Noteice that \n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_df.drop('quality',axis=1), wine_df['quality'], test_size=.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1\n",
    "Use the variables `X_train`, `X_test`, `y_train`, and `y_test` to explore your data. In particular, calculate and display the following information.\n",
    "\n",
    "* Number of samples in the training set in total and in each class.\n",
    "* Number of samples in the testing set in total and in each class.\n",
    "* Number of features in the dataset. \n",
    "* Number of classes in the dataset.\n",
    "* IDs of the number of classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Solution here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2\n",
    "\n",
    "Train an SVM classifier using the `(X_train,y_train)` dataset and use trained model to predict the underlying classes for the observations in the test dataset `X_test`. Store your prediction in a variable called `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3\n",
    "\n",
    "Evaluate the performance of your classifier. Calculate and display the following:\n",
    "* print the `confusion matrix`.\n",
    "* `normalized confusion matrix`. \n",
    "* the probablitity of correct classification (accuracy score). \n",
    "* the `precision`, `recall`, and `f1-score` for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4\n",
    "\n",
    "The code below loads the same dataset, but treats it as a binary classification problem. That is, instead of classifying an observation into one of 10 categories (0..10) instead we consider all observations with score above 5 as being good and all observation below or equal to five as being bad.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to load the data from file. Here we use the pandas library to read the csv file. \n",
    "datafile = \"../data/red-wine-dataset/wineQualityReds.csv\"\n",
    "wine_df = pd.read_csv(datafile)\n",
    "wine_df.drop(wine_df.columns[0],axis=1,inplace=True)\n",
    "\n",
    "wine_df['quality'] = np.where(wine_df['quality']>5,\"Good\",\"Bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(wine_df.drop('quality',axis=1), wine_df['quality'], test_size=.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callenge 4.1\n",
    "Use the variables `X_train`, `X_test`, `y_train`, and `y_test` to explore your data. In particular, calculate and display the following information.\n",
    "* Number of samples in the training set in total and in each class.\n",
    "* Number of samples in the testing set in total and in each class.\n",
    "* Number of features in the dataset. \n",
    "* Number of classes in the dataset.\n",
    "* IDs of the number of classes.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Solution \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 4.2 \n",
    "Train a SVM classifier using the `(X_train,y_train)` dataset and use trained model to predict the underlying classes for the observations in the test dataset `X_test`. Store your prediction in a variable called `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 4.3\n",
    "Evaluate the performance of your classifier. Calculate and display the following:\n",
    "* print the `confusion matrix`.\n",
    "* `normalized confusion matrix`. \n",
    "* the probablitity of correct classification (accuracy score). \n",
    "* the `precision`, `recall`, and `f1-score` for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Solution \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 5\n",
    "\n",
    "SVM classifier accepts a number of parameters. Some of those parameters are the parameter `C`, the `kernel`, the `degree`, and the parameter `gamma`. Evaluate the classifier for different values of K and identify which configuration achieve the best performance on the testing set. Plot or print your results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 6\n",
    "Select the best parameter configuration for the SVM classifier on this dataset (i.e. best C, kernel, gamma or degree parameter configuration). Also choose the best parameter configuration for the KNN classifer. Evaluate both classifiers by by running on 100 random train-test split of the dataset. You can achieve that using a loop (i.e. for loop) and by calleing the `train_test_split` function without specifing the `random_state parameter` to obtain a new random split. For example, the foundation of your code could look like this:\n",
    "\n",
    "```python \n",
    "\n",
    "for i in range(100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(wine_df.drop('quality',axis=1), wine_df['quality'], test_size=.25)\n",
    "\n",
    "##\n",
    "# Your code to train, test and evaluate teh classifier. \n",
    "    \n",
    "```\n",
    "Your code should report the __mean__ and __standard deviation__ of each classifer in terms of __Accuracy__. Base on your finding, which algorithm performs better? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
